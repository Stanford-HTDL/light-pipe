<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>light_pipe API documentation</title>
<meta name="description" content="[Light-Pipe](https://github.com/rcorrero/light-pipe) â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Package <code>light_pipe</code></h1>
</header>
<section id="section-intro">
<h1 id="light-pipe"><a href="https://github.com/rcorrero/light-pipe">Light-Pipe</a></h1>
<hr>
<h2 id="overview">Overview</h2>
<p><a href="https://www.light-pipe.io/">Light-Pipe</a> efficiently creates analysis-ready samples from georeferenced data for use with computer vision models, and provides tools to post-process model outputs and prepare them for interpretation. Light-Pipe is designed to scale effortlessly, being built from the ground-up to support concurrency in all its forms. It's also light-weight, with only one dependency, designed to do its job and get out of the way, and to force as few assumptions as possible on the user. Light-Pipe is released under a <a href="https://opensource.org/licenses/BSD-3-Clause">BSD-3-Clause License</a>. It is currently under heavy development, and every update is liable to break backwards-compatibility.</p>
<p>Light-Pipe's one non-standard Python dependency, the <a href="https://gdal.org/"><code>osgeo</code></a> library, is released under an MIT style open source license by <a href="https://www.osgeo.org/">The Open Source Geospatial Foundation</a>.</p>
<h2 id="comparing-light-pipe-with-existing-packages">Comparing Light-Pipe With Existing Packages</h2>
<h3 id="raster-tiling">Raster Tiling</h3>
<p>Raster files retrieved from data providers, such as satellite images, are generally too large to be input directly into deep-learning-based computer vision models. The <a href="https://arxiv.org/pdf/1512.03385.pdf">ResNet-50 model</a>, for example, requires inputs of size 224 by 224 (measured in pixels) whereas a typical <a href="https://www.usgs.gov/faqs/what-are-band-designations-landsat-satellites">Landsat 8-9 Operational Land Imagery (OLI) panchromatic image</a> is approximately 12200 by 11300 pixels. Therefore, to use a ResNet-50 model with a Landsat image, it is necessary to first pre-process the image. The most straightforward way to do this is to partition the image into image tiles (also known as "chips").</p>
<p>This pre-processing step must be performed <em>every time</em> a satellite image is fed into a model, both while training the model and after it is deployed into production. So when you want to deploy a model to analyze a large number of satellite images, it is vital that your systems can tile images as quickly and efficiently as possible. This is especially true when the goal is to analyze sequences of imagery for each location.</p>
<p>Here, we're concerned with two measures of efficiency: (a) the length of time it takes to process the data, and (b) the amount of storage space necessary to do so. Although Light-Pipe allows the user to save tiles (i.e. write to disk), this is generally undesirable when working with large quantities of data, since doing so may more than double the disk space required to conduct an analysis. For this reason, Light-Pipe can operate in-memory, which means that no extra storage space is required to process data, and you needn't write anything to disk when using it (unless you want to). Such transformations can be performed "on-the-fly", meaning that Light-Pipe transforms input data as it is needed, with no pre-processing step required. As we'll see below, Light-Pipe is so fast that users may prefer to prepare their data on-the-fly rather than in a batch pre-processing step, even during model training.</p>
<p>To test Light-Pipe's performance on this task, let's compare it with existing tools. Although there are other tools for the task of raster tiling, two of the best and most popular are <a href="https://github.com/cogeotiff/rio-tiler"><code>rio-tiler</code></a> and <a href="https://github.com/CosmiQ/solaris"><code>solaris</code></a>. Both have (reasonably) large userbases and feature contributions from skilled developers. As mentioned previously, there are other tools that perform similar functions, but they generally use a similar implementation to one of the two methods tested.</p>
<p>For this test, we'll use the GeoTiff image found <a href="https://s3.amazonaws.com/spacenet-dataset/AOIs/AOI_1_Rio/PS-RGB/PS-RGB_mosaic_013022223133.tif">here</a> (CAUTION, clicking this link will automatically download the file). In the test scripts linked below, this is the file stored at <code>'./data/big_image.tif'</code>. </p>
<p>We'll test two methods of tile generation. The first method simply involves reading sub-arrays from the input image of a specified width and height (in pixels). The second method requires extracting regions from the input image specified in geographic coordinates (e.g. degrees of latitude/longitude), not in pixel coordinates as in the first method. This method is more difficult, as the input image may not use the same coordinate reference system used to specify the coordinates for sub-sampling, and therefore the image may need to be reprojected into the target coordinate reference system first. Also, there are no guarantees in general that the specified coordinates for a region align with the locations of the pixels even after the input image has been reprojected into the same coordinate reference system. Although it is more computationally-expensive to tile according to geographic coordinates rather than pixel coordinates, tiling using geographic coordinates is necessary in general when making imagery sequences with rasters. This means that sequential models such as <a href="https://en.wikipedia.org/wiki/Long_short-term_memory">long short-term memory networks</a> require input tiles which have been subdivided using geographic coordinates, assuming the goal is to generate predictions corresponding to target locations. In short, there are very good reasons to use this approach for tiling since it allows the user to use new classes of models and perform analyses which they couldn't have done otherwise.</p>
<h4 id="results">Results</h4>
<p>Below is a chart displaying the runtime (in seconds) for both Light-Pipe and <code>solaris</code> when extracting sub-regions of an image specified in <em>pixel coordinates</em>. As far as I'm aware it's impossible to perform this task directly using <code>rio-tiler</code>, so it was excluded from this test:</p>
<blockquote>
<p><a href="https://github.com/rcorrero/light-pipe/blob/master/data/plots/test_pixel_tiling.png"><em>Comparison of Runtimes When Using Pixel Coordinates</em></a></p>
</blockquote>
<p><a href="https://github.com/rcorrero/light-pipe/blob/master/data/tests/test_results/test_pixel_tiling.json">Here</a> are the recorded runtimes. These results were generated using <a href="https://github.com/rcorrero/light-pipe/blob/master/tests/test_pixel_tiling.py">this script</a>, which you should test out yourself so that you don't have to take my word for it. These results were obtained on my local machine, which has an AMD Ryzen 5 2600 processor with 16 GB of DDR4 SDRAM and an SDD. Multiple trials were conducted for each method, and the order in which the trials were conducted was randomly-chosen.</p>
<p>Next, I tested the performance of the three methods when extracting sub-regions specified in <em>geographic coordinates</em>:</p>
<blockquote>
<p><a href="https://github.com/rcorrero/light-pipe/blob/master/data/plots/test_geo_tiling.png"><em>Comparison of Runtimes When Using Geographic Coordinates</em></a></p>
</blockquote>
<p><a href="https://github.com/rcorrero/light-pipe/blob/master/data/tests/test_results/test_geo_tiling.json">Here</a> are the recorded runtimes. <a href="https://github.com/rcorrero/light-pipe/blob/master/tests/test_geo_tiling.py">This script</a> was used to obtain these results, and again I performed this test on my local machine.</p>
<p>We see that Light-Pipe handily outperforms the alternatives on both tasks. This test is essentially a <em>worst-case</em> test for Light-Pipe, which is designed with concurrency tools which are most useful when processing large numbers of samples. Here we only process a single sample, giving the other two methods the best possible chance. When training a model, and especially when running a model in production, one may need to process thousands or even millions of images, which is where Light-Pipe's concurrency tools make it extremely attractive. </p>
<p>If you look at the code closely, you'll see that <code>solaris</code> writes (reads) each tile to (from) disk, whereas <code>rio-tiler</code> generates its tiles without writing to disk. Although there are situations in which it is useful to store the tiles for future use, writing tiles to disk can eat up space, prohibitively so if one wants to analyze a large number of images. For example, the size on disk of the sub-regions extracted by <code>solaris</code> using geographic coordinates is approximately 510 MB on my machine, whereas the original image was only 93 MB. That means that image tiling would require over six times as much storage using <code>solaris</code> as would be required when using Light-Pipe. Although <code>rio-tiler</code> does not need to write to disk to make tiles, we see that it is more than an order of magnitude slower than Light-Pipe.</p>
<p>You shouldn't choose to use Light-Pipe solely because it's faster at these tasks, but it should definitely influence your decision-making. There are other reasons why you may want to use it: its clean API, its native concurrency support, its extensibility, its lack of dependencies (except for <code>osgeo</code>), and so on. Light-Pipe allows the user to do things which couldn't be done using any other package. So please give it a go, and if you have any suggestions, don't hesitate to <a href="mailto:rcorrero@stanford.edu">email</a> me or submit a <a href="https://github.com/rcorrero/light-pipe/pulls">pull request</a>.</p>
<h2 id="python-api-guidelines">Python API Guidelines</h2>
<p>The following is a list of guidelines which this package follows:</p>
<ol>
<li>
<p>Light-Pipe handles geospatial data processing and model deployment. It may be used to generate analysis-ready samples on-the-fly during both training and production. Core operations are provided, and abstractions are provided which allow the user to define custom operations.</p>
</li>
<li>
<p>Light-Pipe is geospatially-aware and abstracts away the minutiae of geospatial data, allowing the user to focus instead on model development, training, and evaluation.</p>
</li>
<li>
<p>Light-Pipe also handles <a href="https://en.wikipedia.org/wiki/Concurrency_(computer_science)">concurrency</a>. Light-Pipe is designed from the ground-up to support concurrency in the form of multi-threading, parallelism in the form of multi-processing, and parallelism across multiple machines. This means that all data processing may be scaled arbitrarily to meet the needs of users during both training and deployment.</p>
</li>
<li>
<p>All provided operations are <a href="https://en.wikipedia.org/wiki/Idempotence">idempotent</a> and do not modify any of the input data. References to generated files, such as unique identifiers associated with them, are invariant across repeated operations.</p>
</li>
<li>
<p>All Light-Pipe operations may be performed in memory, with no writing to disk necessary. Generated objects can be written to disk (subject to constraints imposed by the <code>osgeo</code> package).</p>
</li>
<li>
<p>The key abstraction which Light-Pipe presents is the <code>LightPipeline</code> class. Each <code>LightPipeline</code> instance is associated with one or more <code>SampleProcessor</code> instances, each of which defines an operation to be performed on the provided data. The user provides a sequence of <code>SampleProcessor</code>s to a <code>LightPipeline</code> instance which will execute them in order.</p>
</li>
<li>
<p><code>SampleProcessor</code> instances define the operations performed by a <code>LightPipeline</code> on user-provided data and are therefore the basic building blocks of <code>LightPipeline</code>s. Model training or deployment may be incorporated into a <code>LightPipeline</code> by passing a <code>Callable</code> to a <code>SampleProcessor</code> instance or by creating a user-defined subclass of <code>SampleProcessor</code> which performs the desired operations. <code>SampleProcessor</code> is used along with a <code>ConcurrencyHandler</code> instance to deploy a user-provided <code>Callable</code>, optionally wrapped with one or more user-provided wrapper <code>Callable</code>s, in a concurrent manner. Each <code>SampleProcessor</code> instance is itself associated with a <code>ConcurrencyHandler</code> which does exactly what its name suggests: it handles the technicalities of concurrency so that the user doesn't have to. This means that operations associated with <code>SampleProcessor</code>s may be scaled automatically, as required by the user.</p>
</li>
<li>
<p>The <code>ConcurrencyHandler</code> interface consists of two methods, <code>fork</code> and <code>join</code>, names which coincide with their traditional interpretation in <a href="https://en.wikipedia.org/wiki/Fork%E2%80%93join_model">parallel programming contexts</a>. <code>fork</code> operations may be nested recursively, and instances of different <code>ConcurrencyHandler</code> subclasses may be mixed and matched to achieve the desired approach to concurrency (for example, calls to the <code>fork</code> method of a <code>ThreadPoolHandler</code> instance may be nested within calls to the <code>fork</code> method of a <code>ProcessPoolHandler</code> instance). To do so, the user may define custom subclasses of <code>ConcurrencyHandler</code>.</p>
</li>
<li>
<p><code>SampleMaker</code> (a subclass of <code>SampleProcessor</code>) and its subclasses may be used to create <code>LightPipeSample</code> instances. These support key operations such as automatic raster tiling and the saving of user-created data in a georeferenced manner. <code>SampleMaker</code> defines the sequence of operations necessary to produce samples from input files in a concurrent manner (as defined by the supplied <code>ConcurrencyHandler</code> instance).</p>
</li>
<li>
<p><code>LightPipeSample</code> supports tile generation, which allows for the reading of sub-arrays of larger raster data arrays. It also allows for the reading of entire sample arrays. Each tile is associated with a <code>Tile</code> instance from which NumPy arrays may be accessed during training or deployment.</p>
</li>
<li>
<p><code>SampleProcessor</code> instances are designed to ensure that samples are produced and operated on in a manner which is consistent with the requirements imposed by the provided <code>ConcurrencyHandler</code> instance. For example, <code>concurrent.futures</code> requires that objects passed to a <code>ProcessPoolExecutor</code> are <a href="https://docs.python.org/3/library/pickle.html">serializable</a>. In practice this means that generator objects and <code>osgeo.gdal.Dataset</code> instances cannot be passed into or out of a <code>ProcessPoolExecutor</code>, and therefore sample processors must ensure that such objects are neither passed nor returned from processing functions when the <code>ProcessPoolHandler</code> is used.</p>
</li>
<li>
<p>Every operation which can be performed <a href="https://en.wikipedia.org/wiki/Lazy_evaluation">lazily</a> without violating the other guidelines listed here is done so.</p>
</li>
<li>
<p>The user may supply thread pool or process pool objects to <code>ConcurrencyHandler</code>s where necessary, thereby allowing for more control over the degree of concurrency.</p>
</li>
<li>
<p>Every IO operation or calculation is done only once in data processing. There are no duplicate operations, and no data is written to disk except by the user's calling a <code>LightPipeSample</code> instance's <code>save()</code> method. Every operation is designed to be as computationally-efficient as possible.</p>
</li>
<li>
<p>Full support for the <code>osgeo</code> package's virtual file system tools is provided.</p>
</li>
</ol>
<h2 id="more-information">More Information</h2>
<ul>
<li>
<p><a href="https://github.com/rcorrero/light-pipe">GitHub</a></p>
</li>
<li>
<p><a href="https://www.light-pipe.io/">Documentation</a></p>
</li>
</ul>
<hr>
<p>Copyright 2020-2022 <a href="mailto:rcorrero@stanford.edu">Richard Correro</a>.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">__author__ = &#34;Richard Correro(rcorrero@stanford.edu)&#34;

__version__ = &#39;0.1&#39;

__doc__ = &#34;&#34;&#34;

# [Light-Pipe](https://github.com/rcorrero/light-pipe)

---

## Overview

[Light-Pipe](https://www.light-pipe.io/) efficiently creates analysis-ready samples from georeferenced data for use with computer vision models, and provides tools to post-process model outputs and prepare them for interpretation. Light-Pipe is designed to scale effortlessly, being built from the ground-up to support concurrency in all its forms. It&#39;s also light-weight, with only one dependency, designed to do its job and get out of the way, and to force as few assumptions as possible on the user. Light-Pipe is released under a [BSD-3-Clause License](https://opensource.org/licenses/BSD-3-Clause). It is currently under heavy development, and every update is liable to break backwards-compatibility.

Light-Pipe&#39;s one non-standard Python dependency, the [`osgeo`](https://gdal.org/) library, is released under an MIT style open source license by [The Open Source Geospatial Foundation](https://www.osgeo.org/).

## Comparing Light-Pipe With Existing Packages

### Raster Tiling

Raster files retrieved from data providers, such as satellite images, are generally too large to be input directly into deep-learning-based computer vision models. The [ResNet-50 model](https://arxiv.org/pdf/1512.03385.pdf), for example, requires inputs of size 224 by 224 (measured in pixels) whereas a typical [Landsat 8-9 Operational Land Imagery (OLI) panchromatic image](https://www.usgs.gov/faqs/what-are-band-designations-landsat-satellites) is approximately 12200 by 11300 pixels. Therefore, to use a ResNet-50 model with a Landsat image, it is necessary to first pre-process the image. The most straightforward way to do this is to partition the image into image tiles (also known as &#34;chips&#34;).

This pre-processing step must be performed _every time_ a satellite image is fed into a model, both while training the model and after it is deployed into production. So when you want to deploy a model to analyze a large number of satellite images, it is vital that your systems can tile images as quickly and efficiently as possible. This is especially true when the goal is to analyze sequences of imagery for each location.

Here, we&#39;re concerned with two measures of efficiency: (a) the length of time it takes to process the data, and (b) the amount of storage space necessary to do so. Although Light-Pipe allows the user to save tiles (i.e. write to disk), this is generally undesirable when working with large quantities of data, since doing so may more than double the disk space required to conduct an analysis. For this reason, Light-Pipe can operate in-memory, which means that no extra storage space is required to process data, and you needn&#39;t write anything to disk when using it (unless you want to). Such transformations can be performed &#34;on-the-fly&#34;, meaning that Light-Pipe transforms input data as it is needed, with no pre-processing step required. As we&#39;ll see below, Light-Pipe is so fast that users may prefer to prepare their data on-the-fly rather than in a batch pre-processing step, even during model training.

To test Light-Pipe&#39;s performance on this task, let&#39;s compare it with existing tools. Although there are other tools for the task of raster tiling, two of the best and most popular are [`rio-tiler`](https://github.com/cogeotiff/rio-tiler) and [`solaris`](https://github.com/CosmiQ/solaris). Both have (reasonably) large userbases and feature contributions from skilled developers. As mentioned previously, there are other tools that perform similar functions, but they generally use a similar implementation to one of the two methods tested.

For this test, we&#39;ll use the GeoTiff image found [here](https://s3.amazonaws.com/spacenet-dataset/AOIs/AOI_1_Rio/PS-RGB/PS-RGB_mosaic_013022223133.tif) (CAUTION, clicking this link will automatically download the file). In the test scripts linked below, this is the file stored at `&#39;./data/big_image.tif&#39;`. 

We&#39;ll test two methods of tile generation. The first method simply involves reading sub-arrays from the input image of a specified width and height (in pixels). The second method requires extracting regions from the input image specified in geographic coordinates (e.g. degrees of latitude/longitude), not in pixel coordinates as in the first method. This method is more difficult, as the input image may not use the same coordinate reference system used to specify the coordinates for sub-sampling, and therefore the image may need to be reprojected into the target coordinate reference system first. Also, there are no guarantees in general that the specified coordinates for a region align with the locations of the pixels even after the input image has been reprojected into the same coordinate reference system. Although it is more computationally-expensive to tile according to geographic coordinates rather than pixel coordinates, tiling using geographic coordinates is necessary in general when making imagery sequences with rasters. This means that sequential models such as [long short-term memory networks](https://en.wikipedia.org/wiki/Long_short-term_memory) require input tiles which have been subdivided using geographic coordinates, assuming the goal is to generate predictions corresponding to target locations. In short, there are very good reasons to use this approach for tiling since it allows the user to use new classes of models and perform analyses which they couldn&#39;t have done otherwise.

#### Results

Below is a chart displaying the runtime (in seconds) for both Light-Pipe and `solaris` when extracting sub-regions of an image specified in _pixel coordinates_. As far as I&#39;m aware it&#39;s impossible to perform this task directly using `rio-tiler`, so it was excluded from this test:

&gt; [_Comparison of Runtimes When Using Pixel Coordinates_](https://github.com/rcorrero/light-pipe/blob/master/data/plots/test_pixel_tiling.png)

[Here](https://github.com/rcorrero/light-pipe/blob/master/data/tests/test_results/test_pixel_tiling.json) are the recorded runtimes. These results were generated using [this script](https://github.com/rcorrero/light-pipe/blob/master/tests/test_pixel_tiling.py), which you should test out yourself so that you don&#39;t have to take my word for it. These results were obtained on my local machine, which has an AMD Ryzen 5 2600 processor with 16 GB of DDR4 SDRAM and an SDD. Multiple trials were conducted for each method, and the order in which the trials were conducted was randomly-chosen.

Next, I tested the performance of the three methods when extracting sub-regions specified in _geographic coordinates_:

&gt; [_Comparison of Runtimes When Using Geographic Coordinates_](https://github.com/rcorrero/light-pipe/blob/master/data/plots/test_geo_tiling.png)

[Here](https://github.com/rcorrero/light-pipe/blob/master/data/tests/test_results/test_geo_tiling.json) are the recorded runtimes. [This script](https://github.com/rcorrero/light-pipe/blob/master/tests/test_geo_tiling.py) was used to obtain these results, and again I performed this test on my local machine.

We see that Light-Pipe handily outperforms the alternatives on both tasks. This test is essentially a _worst-case_ test for Light-Pipe, which is designed with concurrency tools which are most useful when processing large numbers of samples. Here we only process a single sample, giving the other two methods the best possible chance. When training a model, and especially when running a model in production, one may need to process thousands or even millions of images, which is where Light-Pipe&#39;s concurrency tools make it extremely attractive. 

If you look at the code closely, you&#39;ll see that `solaris` writes (reads) each tile to (from) disk, whereas `rio-tiler` generates its tiles without writing to disk. Although there are situations in which it is useful to store the tiles for future use, writing tiles to disk can eat up space, prohibitively so if one wants to analyze a large number of images. For example, the size on disk of the sub-regions extracted by `solaris` using geographic coordinates is approximately 510 MB on my machine, whereas the original image was only 93 MB. That means that image tiling would require over six times as much storage using `solaris` as would be required when using Light-Pipe. Although `rio-tiler` does not need to write to disk to make tiles, we see that it is more than an order of magnitude slower than Light-Pipe.

You shouldn&#39;t choose to use Light-Pipe solely because it&#39;s faster at these tasks, but it should definitely influence your decision-making. There are other reasons why you may want to use it: its clean API, its native concurrency support, its extensibility, its lack of dependencies (except for `osgeo`), and so on. Light-Pipe allows the user to do things which couldn&#39;t be done using any other package. So please give it a go, and if you have any suggestions, don&#39;t hesitate to [email](mailto:rcorrero@stanford.edu) me or submit a [pull request](https://github.com/rcorrero/light-pipe/pulls).

## Python API Guidelines

The following is a list of guidelines which this package follows:

1. Light-Pipe handles geospatial data processing and model deployment. It may be used to generate analysis-ready samples on-the-fly during both training and production. Core operations are provided, and abstractions are provided which allow the user to define custom operations.

2. Light-Pipe is geospatially-aware and abstracts away the minutiae of geospatial data, allowing the user to focus instead on model development, training, and evaluation.

3. Light-Pipe also handles [concurrency](https://en.wikipedia.org/wiki/Concurrency_(computer_science)). Light-Pipe is designed from the ground-up to support concurrency in the form of multi-threading, parallelism in the form of multi-processing, and parallelism across multiple machines. This means that all data processing may be scaled arbitrarily to meet the needs of users during both training and deployment.

4. All provided operations are [idempotent](https://en.wikipedia.org/wiki/Idempotence) and do not modify any of the input data. References to generated files, such as unique identifiers associated with them, are invariant across repeated operations.

5. All Light-Pipe operations may be performed in memory, with no writing to disk necessary. Generated objects can be written to disk (subject to constraints imposed by the `osgeo` package).

6. The key abstraction which Light-Pipe presents is the `LightPipeline` class. Each `LightPipeline` instance is associated with one or more `SampleProcessor` instances, each of which defines an operation to be performed on the provided data. The user provides a sequence of `SampleProcessor`s to a `LightPipeline` instance which will execute them in order.

7. `SampleProcessor` instances define the operations performed by a `LightPipeline` on user-provided data and are therefore the basic building blocks of `LightPipeline`s. Model training or deployment may be incorporated into a `LightPipeline` by passing a `Callable` to a `SampleProcessor` instance or by creating a user-defined subclass of `SampleProcessor` which performs the desired operations. `SampleProcessor` is used along with a `ConcurrencyHandler` instance to deploy a user-provided `Callable`, optionally wrapped with one or more user-provided wrapper `Callable`s, in a concurrent manner. Each `SampleProcessor` instance is itself associated with a `ConcurrencyHandler` which does exactly what its name suggests: it handles the technicalities of concurrency so that the user doesn&#39;t have to. This means that operations associated with `SampleProcessor`s may be scaled automatically, as required by the user.

8. The `ConcurrencyHandler` interface consists of two methods, `fork` and `join`, names which coincide with their traditional interpretation in [parallel programming contexts](https://en.wikipedia.org/wiki/Fork%E2%80%93join_model). `fork` operations may be nested recursively, and instances of different `ConcurrencyHandler` subclasses may be mixed and matched to achieve the desired approach to concurrency (for example, calls to the `fork` method of a `ThreadPoolHandler` instance may be nested within calls to the `fork` method of a `ProcessPoolHandler` instance). To do so, the user may define custom subclasses of `ConcurrencyHandler`.

9. `SampleMaker` (a subclass of `SampleProcessor`) and its subclasses may be used to create `LightPipeSample` instances. These support key operations such as automatic raster tiling and the saving of user-created data in a georeferenced manner. `SampleMaker` defines the sequence of operations necessary to produce samples from input files in a concurrent manner (as defined by the supplied `ConcurrencyHandler` instance).

10. `LightPipeSample` supports tile generation, which allows for the reading of sub-arrays of larger raster data arrays. It also allows for the reading of entire sample arrays. Each tile is associated with a `Tile` instance from which NumPy arrays may be accessed during training or deployment.

11. `SampleProcessor` instances are designed to ensure that samples are produced and operated on in a manner which is consistent with the requirements imposed by the provided `ConcurrencyHandler` instance. For example, `concurrent.futures` requires that objects passed to a `ProcessPoolExecutor` are [serializable](https://docs.python.org/3/library/pickle.html). In practice this means that generator objects and `osgeo.gdal.Dataset` instances cannot be passed into or out of a `ProcessPoolExecutor`, and therefore sample processors must ensure that such objects are neither passed nor returned from processing functions when the `ProcessPoolHandler` is used.

12. Every operation which can be performed [lazily](https://en.wikipedia.org/wiki/Lazy_evaluation) without violating the other guidelines listed here is done so.

13. The user may supply thread pool or process pool objects to `ConcurrencyHandler`s where necessary, thereby allowing for more control over the degree of concurrency.

14. Every IO operation or calculation is done only once in data processing. There are no duplicate operations, and no data is written to disk except by the user&#39;s calling a `LightPipeSample` instance&#39;s `save()` method. Every operation is designed to be as computationally-efficient as possible.

15. Full support for the `osgeo` package&#39;s virtual file system tools is provided.

## More Information

- [GitHub](https://github.com/rcorrero/light-pipe)

- [Documentation](https://www.light-pipe.io/)

---

Copyright 2020-2022 [Richard Correro](mailto:rcorrero@stanford.edu).
&#34;&#34;&#34;</code></pre>
</details>
</section>
<section>
<h2 class="section-title" id="header-submodules">Sub-modules</h2>
<dl>
<dt><code class="name"><a title="light_pipe.concurrency" href="concurrency/index.html">light_pipe.concurrency</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="light_pipe.gdal_data_handlers" href="gdal_data_handlers.html">light_pipe.gdal_data_handlers</a></code></dt>
<dd>
<div class="desc"><p>The module defines decorators which may be used to handle dataset opening and
closing.</p></div>
</dd>
<dt><code class="name"><a title="light_pipe.gridding" href="gridding.html">light_pipe.gridding</a></code></dt>
<dd>
<div class="desc"><p>This module contains code used to generate standardized grid cell datasets from
arbitrarily-aligned imagery. These datasets are particularly useful in â€¦</p></div>
</dd>
<dt><code class="name"><a title="light_pipe.mercantile" href="mercantile.html">light_pipe.mercantile</a></code></dt>
<dd>
<div class="desc"><p>From: <a href="https://github.com/mapbox/mercantile/blob/fe3762d14001ca400caf7462f59433b906fc25bd/mercantile/__init__.py">https://github.com/mapbox/mercantile/blob/fe3762d14001ca400caf7462f59433b906fc25bd/mercantile/__init__.py</a>
Credit: Mapbox
Original License: â€¦</p></div>
</dd>
<dt><code class="name"><a title="light_pipe.pipeline" href="pipeline.html">light_pipe.pipeline</a></code></dt>
<dd>
<div class="desc"><p>This module contains the definition of <code>LightPipeline</code>, a key component of the
API of this package and the primary method through which the user â€¦</p></div>
</dd>
<dt><code class="name"><a title="light_pipe.processing" href="processing/index.html">light_pipe.processing</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="light_pipe.raster_io" href="raster_io.html">light_pipe.raster_io</a></code></dt>
<dd>
<div class="desc"><p>This module contains utility functions which facilitate file I/O.</p></div>
</dd>
<dt><code class="name"><a title="light_pipe.raster_trans" href="raster_trans.html">light_pipe.raster_trans</a></code></dt>
<dd>
<div class="desc"><p>This module contains functions which operate on <code>gdal.Dataset</code> instances,
<code>ogr.DataSource</code> instances, or create instances of these types.</p></div>
</dd>
<dt><code class="name"><a title="light_pipe.test" href="test/index.html">light_pipe.test</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="light_pipe.tiling" href="tiling.html">light_pipe.tiling</a></code></dt>
<dd>
<div class="desc"><p>This module contains functions necessary to efficiently generate subsample
arrays from groups of raster datasets. Note: in Light-Pipe, <em>tile</em> refers â€¦</p></div>
</dd>
</dl>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul>
<li><a href="#light-pipe">Light-Pipe</a><ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#comparing-light-pipe-with-existing-packages">Comparing Light-Pipe With Existing Packages</a><ul>
<li><a href="#raster-tiling">Raster Tiling</a><ul>
<li><a href="#results">Results</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#python-api-guidelines">Python API Guidelines</a></li>
<li><a href="#more-information">More Information</a></li>
</ul>
</li>
</ul>
</div>
<ul id="index">
<li><h3><a href="#header-submodules">Sub-modules</a></h3>
<ul>
<li><code><a title="light_pipe.concurrency" href="concurrency/index.html">light_pipe.concurrency</a></code></li>
<li><code><a title="light_pipe.gdal_data_handlers" href="gdal_data_handlers.html">light_pipe.gdal_data_handlers</a></code></li>
<li><code><a title="light_pipe.gridding" href="gridding.html">light_pipe.gridding</a></code></li>
<li><code><a title="light_pipe.mercantile" href="mercantile.html">light_pipe.mercantile</a></code></li>
<li><code><a title="light_pipe.pipeline" href="pipeline.html">light_pipe.pipeline</a></code></li>
<li><code><a title="light_pipe.processing" href="processing/index.html">light_pipe.processing</a></code></li>
<li><code><a title="light_pipe.raster_io" href="raster_io.html">light_pipe.raster_io</a></code></li>
<li><code><a title="light_pipe.raster_trans" href="raster_trans.html">light_pipe.raster_trans</a></code></li>
<li><code><a title="light_pipe.test" href="test/index.html">light_pipe.test</a></code></li>
<li><code><a title="light_pipe.tiling" href="tiling.html">light_pipe.tiling</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>